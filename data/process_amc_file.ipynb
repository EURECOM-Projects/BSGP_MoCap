{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "\n",
    "def read_amc_file(file_path):\n",
    "    print('Reading file %s'%file_path)\n",
    "    num_sensors = 29\n",
    "    walk_timeseries_data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.read().splitlines() # Each line is a list of elements\n",
    "        lines = lines[3:]\n",
    "        p = 0 # index in lines\n",
    "        while True: # Each line in [lines] is 'sensor_name sensor_data\n",
    "            timestamp = int(lines[p])\n",
    "            timestamp_data = []\n",
    "\n",
    "            for i in range(num_sensors):\n",
    "                sensor_line = lines[p+i+1].split(' ') # Read from p + i + 1 line (measurement of first sensor of timestamp p)\n",
    "                next = False\n",
    "                sensor_data = []\n",
    "                k = 1\n",
    "                while next == False:  # Reading sensor data\n",
    "                    try:\n",
    "                        s = float(sensor_line[k])\n",
    "                        sensor_data.append(s)\n",
    "                        k += 1\n",
    "                    except:\n",
    "                        next = True\n",
    "                timestamp_data.append(sensor_data) \n",
    "                \n",
    "            walk_timeseries_data.append(timestamp_data)\n",
    "            p += num_sensors + 1\n",
    "            if p >= len(lines):\n",
    "                break\n",
    "        return walk_timeseries_data\n",
    "\n",
    "def column_pca(walk_timeseries_data, rowshape=False):\n",
    "    pca = PCA(1)\n",
    "    num_sensors = 29 # D\n",
    "    walk_timeseries_data_pca = np.empty((len(walk_timeseries_data), num_sensors)) # T x D\n",
    "    j = 0\n",
    "    for sensor in range(num_sensors):\n",
    "        sensor_data_over_time = np.array([walk_timeseries_data[i][sensor] for i in range(len(walk_timeseries_data))]) # T x M, M:[1..6]\n",
    "        if sensor_data_over_time.shape[1] > 1: # M > 1\n",
    "            sensor_data_over_time_pca = pca.fit_transform(sensor_data_over_time) # T x 1\n",
    "        else:\n",
    "            sensor_data_over_time_pca = sensor_data_over_time # M == 1\n",
    "        walk_timeseries_data_pca[:, j:j+1] = sensor_data_over_time_pca\n",
    "        j += 1\n",
    "    if rowshape:\n",
    "        walk_timeseries_data_pca = walk_timeseries_data_pca.reshape(walk_timeseries_data_pca.shape[0]*walk_timeseries_data_pca.shape[1]) # (1, T*D) shape\n",
    "    return walk_timeseries_data_pca\n",
    "\n",
    "def build_dataset_long(X):\n",
    "    limit_time = 100 # T\n",
    "    num_sensors = 29 # D\n",
    "    nrows = limit_time * len(X)\n",
    "    X_pca = np.empty((nrows, num_sensors)) # NT x D\n",
    "    i = 0\n",
    "    for walk_timeseries_data in X:\n",
    "        # apply column-PCA separately to each file/time-series\n",
    "        walk_timeseries_data_pca = column_pca(walk_timeseries_data, rowshape=False)[:limit_time,:] # T x D\n",
    "        X_pca[i:i+limit_time, :] = walk_timeseries_data_pca\n",
    "        i += limit_time \n",
    "    return X_pca\n",
    "\n",
    "def build_dataset_wide_full(X, T):\n",
    "    limit_time = T # T\n",
    "    nrows = len(X)\n",
    "    num_sensors = 29\n",
    "    D = 62\n",
    "    X_full = np.empty((nrows, limit_time*D)) # N x TD\n",
    "    j = 0\n",
    "    for walk_timeseries_data in X: # for each file/time-series\n",
    "        file_measures = []\n",
    "        for t in range(limit_time):\n",
    "            file_measures_time_t = []\n",
    "            for i in range(num_sensors):\n",
    "                file_measures_time_t.append(walk_timeseries_data[t][i])\n",
    "            file_measures_time_t = np.array([m for sublist in file_measures_time_t for m in sublist]) # D,\n",
    "            file_measures.append(file_measures_time_t)\n",
    "        X_full[j:j+1,:] = np.concatenate(file_measures, axis=0).reshape(1,-1)\n",
    "        j += 1\n",
    "    return X_full\n",
    "\n",
    "def build_dataset_wide(X):\n",
    "    limit_time = 100\n",
    "    num_sensors = 29\n",
    "    ncols = num_sensors * limit_time\n",
    "    X_pca = np.empty((len(X), num_sensors * limit_time)) # N x TD\n",
    "    i = 0\n",
    "    for walk_timeseries_data in X:\n",
    "        walk_timeseries_data_pca = column_pca(walk_timeseries_data, rowshape=True)[:ncols] # 1 x TD\n",
    "        X_pca[i:i+1, :] = walk_timeseries_data_pca.reshape(1,-1)\n",
    "        i += 1\n",
    "    return X_pca\n",
    "\n",
    "def build_dataset_tensor(X):\n",
    "    limit_time = 100\n",
    "    num_sensors = 29\n",
    "    N = len(X)\n",
    "    X_pca = np.empty((N, limit_time, num_sensors))  # N x T x D\n",
    "    i = 0\n",
    "    for walk_timeseries_data in X:\n",
    "        walk_timeseries_data_pca = column_pca(walk_timeseries_data, rowshape=False)[:limit_time,:] # T x D\n",
    "        X_pca[i:i+1, :, :] = walk_timeseries_data_pca\n",
    "        i += 1\n",
    "    return X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file walk/15_03.amc\n",
      "Reading file walk/07_03.amc\n",
      "Reading file walk/07_02.amc\n",
      "Reading file walk/16_47.amc\n",
      "Reading file walk/15_14.amc\n",
      "Reading file walk/07_01.amc\n",
      "Reading file walk/15_01.amc\n",
      "Reading file walk/07_05.amc\n",
      "Reading file walk/07_11.amc\n",
      "Reading file walk/07_10.amc\n",
      "Reading file walk/07_04.amc\n",
      "Reading file walk/05_01.amc\n",
      "Reading file walk/07_12.amc\n",
      "Reading file walk/07_06.amc\n",
      "Reading file walk/07_07.amc\n",
      "Reading file walk/16_31.amc\n",
      "Reading file walk/16_25.amc\n",
      "Reading file walk/16_19.amc\n",
      "Reading file walk/16_18.amc\n",
      "Reading file walk/16_24.amc\n",
      "Reading file walk/16_30.amc\n",
      "Reading file walk/16_26.amc\n",
      "Reading file walk/16_32.amc\n",
      "Reading file walk/16_33.amc\n",
      "Reading file walk/16_27.amc\n",
      "Reading file walk/16_23.amc\n",
      "Reading file walk/16_22.amc\n",
      "Reading file walk/16_34.amc\n",
      "Reading file walk/16_20.amc\n",
      "Reading file walk/08_08.amc\n",
      "Reading file walk/08_09.amc\n",
      "Reading file walk/16_21.amc\n",
      "Reading file walk/06_01.amc\n",
      "Reading file walk/08_10.amc\n",
      "Reading file walk/08_05.amc\n",
      "Reading file walk/08_11.amc\n",
      "Reading file walk/16_11.amc\n",
      "Reading file walk/16_13.amc\n",
      "Reading file walk/08_06.amc\n",
      "Reading file walk/16_12.amc\n",
      "Reading file walk/16_16.amc\n",
      "Reading file walk/08_02.amc\n",
      "Reading file walk/08_03.amc\n",
      "Reading file walk/16_17.amc\n",
      "Reading file walk/16_29.amc\n",
      "Reading file walk/16_15.amc\n",
      "Reading file walk/08_01.amc\n",
      "Reading file walk/16_14.amc\n",
      "Reading file walk/16_28.amc\n",
      "Reading file walk/12_03.amc\n",
      "Reading file walk/12_02.amc\n",
      "Reading file walk/16_58.amc\n",
      "Reading file walk/15_09.amc\n",
      "Reading file walk/07_09.amc\n",
      "Reading file walk/07_08.amc\n",
      "Reading file walk/10_04.amc\n",
      "Reading file walk/12_01.amc\n",
      "Reading file walk/02_01.amc\n",
      "Reading file walk/02_02.amc\n"
     ]
    }
   ],
   "source": [
    "# Read walk files\n",
    "X = []\n",
    "for filename in os.listdir('walk/'):\n",
    "    if filename.endswith(\".amc\") and filename.startswith(\"07\"):\n",
    "        file_path = os.path.join('walk/', filename)\n",
    "        walk_timeseries_data = read_amc_file(file_path)\n",
    "        X.append(walk_timeseries_data)\n",
    "        #walk_timeseries_data_pca = column_pca(walk_timeseries_data)\n",
    "# NOTE: SUBJECT 07_12 THERE WAS NOT ltoes MEASUREMENT FOR THE LAST TIMESTAMP, I PUT IT EQUAL TO THE PREVIOUS TIMESTAMP\n",
    "\n",
    "\n",
    "T = 100 # -> I fixed a limit on the number of timestaps i consider for each file \n",
    "N = len(X) # of files (samples)\n",
    "D = 62\n",
    "X_NxTD_walk = build_dataset_wide_full(X, T) # N x TD [D=62]\n",
    "X_NTxD_walk = X_NxTD_walk.reshape(N*T,D) # TD x N [D=62]\n",
    "#X_long_walk = build_dataset_long(X) # NT x D [D=29]\n",
    "#X_wide_walk = build_dataset_wide(X) # N x TD [D=29]\n",
    "#X_tensor_walk = build_dataset_tensor(X) # N x T x D [D=29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file run/16_52.amc\n",
      "Reading file run/16_46.amc\n",
      "Reading file run/09_06.amc\n",
      "Reading file run/09_07.amc\n",
      "Reading file run/16_53.amc\n",
      "Reading file run/16_45.amc\n",
      "Reading file run/16_51.amc\n",
      "Reading file run/09_11.amc\n",
      "Reading file run/09_05.amc\n",
      "Reading file run/09_04.amc\n",
      "Reading file run/09_10.amc\n",
      "Reading file run/16_50.amc\n",
      "Reading file run/16_44.amc\n",
      "Reading file run/16_40.amc\n",
      "Reading file run/16_54.amc\n",
      "Reading file run/09_01.amc\n",
      "Reading file run/16_55.amc\n",
      "Reading file run/16_41.amc\n",
      "Reading file run/16_57.amc\n",
      "Reading file run/16_43.amc\n",
      "Reading file run/09_03.amc\n",
      "Reading file run/09_02.amc\n",
      "Reading file run/16_42.amc\n",
      "Reading file run/16_56.amc\n",
      "Reading file run/16_37.amc\n",
      "Reading file run/35_17.amc\n",
      "Reading file run/16_36.amc\n",
      "Reading file run/16_08.amc\n",
      "Reading file run/16_35.amc\n",
      "Reading file run/16_38.amc\n",
      "Reading file run/35_18.amc\n",
      "Reading file run/35_24.amc\n",
      "Reading file run/35_25.amc\n",
      "Reading file run/35_19.amc\n",
      "Reading file run/16_39.amc\n",
      "Reading file run/35_26.amc\n",
      "Reading file run/35_22.amc\n",
      "Reading file run/35_23.amc\n",
      "Reading file run/35_21.amc\n",
      "Reading file run/35_20.amc\n",
      "Reading file run/16_49.amc\n",
      "Reading file run/09_09.amc\n",
      "Reading file run/09_08.amc\n",
      "Reading file run/16_48.amc\n",
      "Reading file run/02_03.amc\n",
      "Reading file run/38_03.amc\n"
     ]
    }
   ],
   "source": [
    "# Read run files\n",
    "X = []\n",
    "for filename in os.listdir('run/'):\n",
    "    if filename.endswith(\".amc\"):\n",
    "        file_path = os.path.join('run/', filename)\n",
    "        walk_timeseries_data = read_amc_file(file_path)\n",
    "        X.append(walk_timeseries_data)\n",
    "N = len(X)\n",
    "T = 100\n",
    "D = 62\n",
    "X_NxTD_run = build_dataset_wide_full(X, T) # N x TD [D=62]\n",
    "X_NTxD_run = X_NxTD_run.reshape(N*T,D) # TD x N [D=62]\n",
    "#X_long_run = build_dataset_long(X) # NT x D\n",
    "#X_wide_run = build_dataset_wide(X) # N x TD\n",
    "#X_wide_run_full = build_dataset_wide_full(X) # N x TD [D=62]\n",
    "#X_tensor_run = build_dataset_tensor(X) # N x T x D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N.walk =  59\n",
      "N.run =  46\n"
     ]
    }
   ],
   "source": [
    "# Merge data\n",
    "Y_walk = np.zeros(X_NxTD_walk.shape[0])\n",
    "Y_run = np.ones(X_NxTD_run.shape[0])\n",
    "Y = np.concatenate((Y_walk, Y_run)).reshape(-1,1)\n",
    "X_NxTD = np.vstack((X_NxTD_walk, X_NxTD_run))\n",
    "X_NTxD = np.vstack((X_NTxD_walk, X_NTxD_run))\n",
    "print('N.walk = ', X_NxTD_walk.shape[0])\n",
    "print('N.run = ', X_NxTD_run.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sensor labels\n",
    "sensors_names = ['root','lowerback','upperback','thorax','lowerneck','upperneck','head','rclavicle','rhumerus','rradius','rwrist','rhand','rfingers','rthumb','lclavicle','lhumerus','lradius','lwrist','lhand','lfingers','lthumb','rfemur','rtibia','rfoot','rtoes','lfemur','ltibia','lfoot','ltoes']\n",
    "s_mask = []\n",
    "for sensor_j_measure in X[0][0]:\n",
    "    s_mask.append(len(sensor_j_measure))\n",
    "s_names_mask = []\n",
    "for i, sensor_name in enumerate(sensors_names):\n",
    "    s_names_mask.append([sensor_name] * s_mask[i])\n",
    "s_names_mask_flat = []\n",
    "for row in s_names_mask:\n",
    "    s_names_mask_flat.extend(row)\n",
    "sensors_names = np.array(s_names_mask_flat) \n",
    "sensors_mask = np.cumsum(np.array(s_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('mocap_data.npz', X_NxTD=X_NxTD, X_NTxD=X_NTxD, Y=Y, sensors_names=sensors_names, sensors_mask=sensors_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
