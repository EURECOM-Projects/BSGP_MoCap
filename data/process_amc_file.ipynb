{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "\n",
    "def read_amc_file(file_path):\n",
    "    print('Reading file %s'%file_path)\n",
    "    num_sensors = 29\n",
    "    walk_timeseries_data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.read().splitlines() # Each line is a list of elements\n",
    "        lines = lines[3:]\n",
    "        p = 0 # index in lines\n",
    "        while True: # Each line in [lines] is 'sensor_name sensor_data\n",
    "            timestamp = int(lines[p])\n",
    "            timestamp_data = []\n",
    "\n",
    "            for i in range(num_sensors):\n",
    "                sensor_line = lines[p+i+1].split(' ') # Read from p + i + 1 line (measurement of first sensor of timestamp p)\n",
    "                next = False\n",
    "                sensor_data = []\n",
    "                k = 1\n",
    "                while next == False:  # Reading sensor data\n",
    "                    try:\n",
    "                        s = float(sensor_line[k])\n",
    "                        sensor_data.append(s)\n",
    "                        k += 1\n",
    "                    except:\n",
    "                        next = True\n",
    "                timestamp_data.append(sensor_data) \n",
    "                \n",
    "            walk_timeseries_data.append(timestamp_data)\n",
    "            p += num_sensors + 1\n",
    "            if p >= len(lines):\n",
    "                break\n",
    "        return walk_timeseries_data\n",
    "\n",
    "def column_pca(walk_timeseries_data, rowshape=False):\n",
    "    pca = PCA(1)\n",
    "    num_sensors = 29\n",
    "    walk_timeseries_data_pca = np.empty((len(walk_timeseries_data), num_sensors))\n",
    "    i = 0\n",
    "    for sensor in range(num_sensors):\n",
    "        sensor_data_over_time = np.array([walk_timeseries_data[i][sensor] for i in range(len(walk_timeseries_data))])\n",
    "        if sensor_data_over_time.shape[1] > 1:\n",
    "            sensor_data_over_time_pca = pca.fit_transform(sensor_data_over_time)\n",
    "        else:\n",
    "            sensor_data_over_time_pca = sensor_data_over_time\n",
    "        walk_timeseries_data_pca[:, i:i+1] = sensor_data_over_time_pca\n",
    "        i += 1\n",
    "    if rowshape:\n",
    "        walk_timeseries_data_pca = walk_timeseries_data_pca.reshape(walk_timeseries_data_pca.shape[0]*walk_timeseries_data_pca.shape[1]) # (1, T*D) shape\n",
    "    return walk_timeseries_data_pca\n",
    "\n",
    "def build_dataset_long(X):\n",
    "    limit_time = 100\n",
    "    num_sensors = 29\n",
    "    nrows = limit_time * len(X)\n",
    "    X_pca = np.empty((nrows, num_sensors))\n",
    "    i = 0\n",
    "    for walk_timeseries_data in X:\n",
    "        walk_timeseries_data_pca = column_pca(walk_timeseries_data)[:limit_time,:]\n",
    "        X_pca[i:i+limit_time, :] = walk_timeseries_data_pca\n",
    "        i += limit_time \n",
    "    return X_pca\n",
    "\n",
    "def build_dataset_wide(X):\n",
    "    limit_time = 100\n",
    "    num_sensors = 29\n",
    "    ncols = num_sensors * limit_time\n",
    "    X_pca = np.empty((len(X), num_sensors * limit_time))\n",
    "    i = 0\n",
    "    for walk_timeseries_data in X:\n",
    "        walk_timeseries_data_pca = column_pca(walk_timeseries_data, rowshape=True)[:ncols]\n",
    "        X_pca[i:i+1, :] = walk_timeseries_data_pca.reshape(1,-1)\n",
    "        i += 1\n",
    "    return X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file walk/07_03.amc\n",
      "Reading file walk/07_02.amc\n",
      "Reading file walk/07_01.amc\n",
      "Reading file walk/07_05.amc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file walk/07_11.amc\n",
      "Reading file walk/07_10.amc\n",
      "Reading file walk/07_04.amc\n",
      "Reading file walk/07_12.amc\n",
      "Reading file walk/07_06.amc\n",
      "Reading file walk/07_07.amc\n",
      "Reading file walk/08_08.amc\n",
      "Reading file walk/08_09.amc\n",
      "Reading file walk/08_10.amc\n",
      "Reading file walk/08_05.amc\n",
      "Reading file walk/08_11.amc\n",
      "Reading file walk/08_06.amc\n",
      "Reading file walk/08_02.amc\n",
      "Reading file walk/08_03.amc\n",
      "Reading file walk/08_01.amc\n",
      "Reading file walk/07_09.amc\n",
      "Reading file walk/07_08.amc\n"
     ]
    }
   ],
   "source": [
    "# Read walk files\n",
    "X = []\n",
    "for filename in os.listdir('walk/'):\n",
    "    if filename.endswith(\".amc\"):\n",
    "        file_path = os.path.join('walk/', filename)\n",
    "        walk_timeseries_data = read_amc_file(file_path)\n",
    "        X.append(walk_timeseries_data)\n",
    "        #walk_timeseries_data_pca = column_pca(walk_timeseries_data)\n",
    "# NOTE: SUBJECT 07_12 THERE WAS NOT ltoes MEASUREMENT FOR THE LAST TIMESTAMP, I PUT IT EQUAL TO THE PREVIOUS TIMESTAMP\n",
    "\n",
    "# N = 100 -> I fixed a limit on the number of timestaps i consider for each file \n",
    "X_long_walk = build_dataset_long(X) # NT x D\n",
    "X_wide_walk = build_dataset_wide(X) # N x TD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file run/16_46.amc\n",
      "Reading file run/09_06.amc\n",
      "Reading file run/09_07.amc\n",
      "Reading file run/16_45.amc\n",
      "Reading file run/09_11.amc\n",
      "Reading file run/09_05.amc\n",
      "Reading file run/09_04.amc\n",
      "Reading file run/09_10.amc\n",
      "Reading file run/09_01.amc\n",
      "Reading file run/16_55.amc\n",
      "Reading file run/16_57.amc\n",
      "Reading file run/09_03.amc\n",
      "Reading file run/09_02.amc\n",
      "Reading file run/16_56.amc\n",
      "Reading file run/16_36.amc\n",
      "Reading file run/16_35.amc\n",
      "Reading file run/09_09.amc\n",
      "Reading file run/09_08.amc\n"
     ]
    }
   ],
   "source": [
    "# Read run files\n",
    "X = []\n",
    "for filename in os.listdir('run/'):\n",
    "    if filename.endswith(\".amc\"):\n",
    "        file_path = os.path.join('run/', filename)\n",
    "        walk_timeseries_data = read_amc_file(file_path)\n",
    "        X.append(walk_timeseries_data)\n",
    "\n",
    "# N = 100 -> I fixed a limit on the number of timestaps i consider for each file \n",
    "X_long_run = build_dataset_long(X) # NT x D\n",
    "X_wide_run = build_dataset_wide(X) # N x TD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data\n",
    "Y_walk = np.zeros(X_wide_walk.shape[0])\n",
    "Y_run = np.ones(X_wide_run.shape[0])\n",
    "Y_walk_run = np.concatenate((Y_walk, Y_run))\n",
    "X_wide_walk_run = np.vstack((X_wide_walk, X_wide_run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and save data\n",
    "X_wide_walk_run = (X_wide_walk_run - np.mean(X_wide_walk_run, axis=0)) / np.std(X_wide_walk_run, axis=0)\n",
    "Y = Y_walk_run.reshape(-1,1)\n",
    "inputs = torch.tensor(X_wide_walk_run, dtype=torch.float64)\n",
    "targets = torch.tensor(Y, dtype=torch.float64)\n",
    "torch.save([inputs, targets], './' + 'mocap' + '.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
